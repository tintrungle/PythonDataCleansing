{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "covidtotals = pd.read_csv('data/covidtotals.csv',\n",
    "                          parse_dates=['lastdate'])\n",
    "covidtotals.set_index('iso_code', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comment out OpenAI imports and code\n",
    "# from pandasai.llm.openai import OpenAI\n",
    "# from pandasai import SmartDataframe\n",
    "# llm = OpenAI(api_token=\"Your API Key\")\n",
    "# covidtotalssdf = SmartDataframe(covidtotals, config={\"llm\": llm})\n",
    "# covidtotalssdf.chat(\"Show me some information about the data\")\n",
    "\n",
    "\n",
    "\n",
    "# Configure Gemini API\n",
    "GOOGLE_API_KEY = 'AIzaSyCz0sJjoIyzejmnpcaSD-fdsar5PL-PNU0'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-04-17\n",
      "models/gemini-2.5-flash-preview-04-17-thinking\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/veo-2.0-generate-001\n",
      "models/gemini-2.0-flash-live-001\n"
     ]
    }
   ],
   "source": [
    "# List available models\n",
    "for m in genai.list_models():\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's some information about the provided data, covering various aspects:\n",
      "\n",
      "**General Overview:**\n",
      "\n",
      "* **Type:** The data appears to be epidemiological data related to COVID-19 cases, deaths, and other demographic and economic factors for various countries/regions.\n",
      "* **Format:** It's likely a Pandas DataFrame (from Python) judging by the `iso_code` index and the structure.\n",
      "* **Scope:** The data covers a wide range of countries/regions globally, as evidenced by the ISO codes (e.g., AFG, ALB, USA, etc.).\n",
      "* **Timeframe:** The `lastdate` column indicates that the data was collected at different points in time for different locations, ranging from as early as 2020 to 2024. This inconsistency in reporting dates is crucial to consider in any analysis.\n",
      "\n",
      "**Variables:**\n",
      "\n",
      "* **Epidemiological:**\n",
      "    * `total_cases`: Total number of confirmed COVID-19 cases.\n",
      "    * `total_deaths`: Total number of confirmed COVID-19 deaths.\n",
      "    * `total_cases_pm`: Total cases per million population.\n",
      "    * `total_deaths_pm`: Total deaths per million population.\n",
      "    * `vac_per_hund`:  Vaccination per hundred likely, but missing data makes it hard to confirm.\n",
      "* **Demographic:**\n",
      "    * `population`: Total population of the location.\n",
      "    * `pop_density`: Population density (people per square kilometer/mile - units unclear).\n",
      "    * `median_age`: Median age of the population.\n",
      "    * `aged_65_older`: Percentage of the population aged 65 and older.\n",
      "    * `life_expectancy`: Life expectancy at birth.\n",
      "* **Economic:**\n",
      "    * `gdp_per_capita`: GDP per capita (likely in US dollars, but units not specified).\n",
      "* **Healthcare:**\n",
      "    * `hosp_beds`: Hospital beds per 1,000 people.\n",
      "* **Geographic:**\n",
      "    * `location`: Name of the country/region.\n",
      "    * `region`: Broader geographical region the location belongs to.\n",
      "\n",
      "\n",
      "**Data Quality Issues:**\n",
      "\n",
      "* **Missing Data (NaN):**  Several columns have missing values (NaN), especially `vac_per_hund`, `hosp_beds`,  and some demographic data for smaller territories. This needs to be addressed before analysis (e.g., imputation or removal).\n",
      "* **Inconsistent Reporting Dates (`lastdate`):** As mentioned earlier, the dates of the last reported data point vary significantly. This makes direct comparisons between locations problematic and could lead to misleading conclusions if not handled carefully.  It might require finding data from a consistent time point or working with time series data for accurate analysis.\n",
      "* **Units:**  While some units can be inferred (e.g., `gdp_per_capita` likely in USD), clarity on units for all variables is crucial for interpretation and analysis.\n",
      "\n",
      "\n",
      "\n",
      "**Potential Analysis:**\n",
      "\n",
      "The data offers several avenues for exploration:\n",
      "\n",
      "* **Correlation analysis:** Investigate relationships between variables (e.g., `total_cases_pm` and `pop_density`, `gdp_per_capita` and `life_expectancy`).\n",
      "* **Regional comparisons:**  Compare epidemiological statistics and other factors across different regions (`region`).\n",
      "* **Impact of demographics/economics:**  Study the influence of demographic and economic factors on COVID-19 outcomes.\n",
      "* **Time series analysis (if consistent data is available):**  Analyze trends in cases, deaths, and other variables over time.\n",
      "\n",
      "Before proceeding with any analysis, it's highly recommended to clean the data, handle missing values, and address the issue of inconsistent reporting dates to ensure the reliability of the findings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using Gemini\n",
    "def analyze_with_gemini(data, prompt):\n",
    "    # Convert data to string format for Gemini\n",
    "    data_str = data.to_string()\n",
    "    \n",
    "    # Create full prompt\n",
    "    full_prompt = f\"\"\"\n",
    "    Please analyze the following data:\n",
    "    \n",
    "    Data:\n",
    "    {data_str}\n",
    "    \n",
    "    Question: {prompt}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate analysis using Gemini\n",
    "    response = model.generate_content(full_prompt)\n",
    "    return response.text\n",
    "\n",
    "# Get information about the data\n",
    "analysis = analyze_with_gemini(covidtotals, \"Show me some information about the data\")\n",
    "print(analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
